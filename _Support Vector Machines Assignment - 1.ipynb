{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363df562-51ca-4e95-a4f9-663b74bd949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the mathematical formula for a linear SVM?\n",
    "Ans:The mathematical formula for a linear SVM is a hyperplane that separates the data points into two classes. This hyperplane can be represented as:   \n",
    "\n",
    "w^T * x + b = 0\n",
    "Where:\n",
    "\n",
    "w: is a weight vector, perpendicular to the hyperplane.\n",
    "x: is a data point.\n",
    "b: is the bias term, determining the offset of the hyperplane from the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df36529-2458-4a64-b75c-f8e1d6ac5aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the objective function of a linear SVM?\n",
    "Ans:The objective function of a linear SVM is to maximize the margin between the separating hyperplane and the closest data points from each class, while ensuring that all data points are correctly classified. Mathematically, it can be expressed as a constrained optimization problem:   \n",
    "\n",
    "Objective Function:\n",
    "\n",
    "Minimize: 1/2 * ||w||^2\n",
    "Subject to:\n",
    "\n",
    "yi * (w^T * xi + b) >= 1, for all i\n",
    "Where:\n",
    "\n",
    "w: is the weight vector, perpendicular to the hyperplane.\n",
    "b: is the bias term, determining the offset of the hyperplane from the origin.\n",
    "yi: is the class label of the i-th data point (either +1 or -1).\n",
    "xi: is the i-th data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a7c7cc-389d-4003-aa33-c583f7647d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is the kernel trick in SVM?\n",
    "Ans:The kernel trick is a technique used in Support Vector Machines (SVMs) to implicitly map data points from a lower-dimensional space to a higher-dimensional feature space, where they may be linearly separable.\n",
    "\n",
    " This allows SVMs to handle complex, non-linear relationships between data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2653e4-9bf3-4b39-990e-18d64055b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is the role of support vectors in SVM Explain with example\n",
    "Ans:Support Vectors: The Backbone of SVM\n",
    "\n",
    "Support vectors are the data points that lie closest to the decision boundary of an SVM. They play a crucial role in defining the optimal hyperplane and the margin.\n",
    "\n",
    "Defining the Decision Boundary:\n",
    "\n",
    "The position of the hyperplane is determined by the support vectors.\n",
    "Moving a support vector even slightly can shift the position of the hyperplane.\n",
    "Data points that are not support vectors have no influence on the hyperplane's position.\n",
    "Maximizing the Margin:\n",
    "\n",
    "The margin, the distance between the hyperplane and the closest data points, is maximized by considering only the support vectors.\n",
    "A larger margin generally leads to better generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc854633-4d0f-4d9f-9eb3-37830d1d4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Illustrate with examples and graphs of Hyperplane, Marginal plane, Soft margin and Hard margin in\n",
    "SVM?\n",
    "Ans:Hyperplane, Marginal Planes, Soft Margin, and Hard Margin in SVM\n",
    "Hyperplane\n",
    "A hyperplane is a decision boundary that separates data points into different classes. In a 2D space, it a line. In higher dimensions, it's a higher-dimensional plane.\n",
    "Opens in a new window\n",
    "www.researchgate.net\n",
    "hyperplane separating two classes of data points in a 2D space\n",
    "\n",
    "Marginal Planes\n",
    "Marginal planes are two parallel hyperplanes that define the boundaries of the margin. The distance between these planes is maximized to ensure optimal separation between the classes.\n",
    "Opens in a new window\n",
    "www.researchgate.net\n",
    "hyperplane with marginal planes, showing the margin\n",
    "\n",
    "Hard Margin SVM\n",
    "A hard margin SVM aims to find the optimal hyperplane that perfectly separates the data points without any misclassifications. This approach is ideal when the data is linearly separable. However, it can be sensitive to outliers and noise in the data.\n",
    "Opens in a new window\n",
    "www.geeksforgeeks.org\n",
    "hard margin SVM with a perfectly separating hyperplane\n",
    "\n",
    "Soft Margin SVM\n",
    "A soft margin SVM allows for some misclassifications to handle noisy or overlapping data. It introduces a penalty term in the optimization function to balance the margin maximization and misclassification minimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815929d9-f4dc-4370-91a3-97a85c9b5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. SVM Implementation through Iris dataset.\n",
    "\n",
    "Bonus task: Implement a linear SVM classifier from scratch using Python and compare its\n",
    "performance with the scikit-learn implementation.\n",
    "~ Load the iris dataset from the scikit-learn library and split it into a training set and a testing setl\n",
    "~ Train a linear SVM classifier on the training set and predict the labels for the testing setl\n",
    "~ Compute the accuracy of the model on the testing setl\n",
    "~ Plot the decision boundaries of the trained model using two of the featuresl\n",
    "~ Try different values of the regularisation parameter C and see how it affects the performance of\n",
    "the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57bf6a-28a1-41a3-b0a8-623070642ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
