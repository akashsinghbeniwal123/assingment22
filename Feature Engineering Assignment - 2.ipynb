{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4591c-6bc4-420e-9a07-2633646b733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application.\n",
    "Ans:Min-Max Scaling is a normalization technique used in data preprocessing to scale numerical features to a specific range, typically between 0 and 1. It is useful when the data has varying scales and when it is important to have features on a comparable scale.\n",
    "\n",
    "How Min-Max Scaling Works:\n",
    "\n",
    "Find the minimum and maximum values: Determine the minimum and maximum values for each feature in the dataset.\n",
    "Rescale the data: For each feature, subtract the minimum value and divide by the range (maximum value - minimum value). This transforms the values to a scale between 0 and 1.\n",
    "Example:\n",
    "\n",
    "Suppose you have a dataset with two features: age and income. The age feature ranges from 20 to 60, and the income feature ranges from 30,000 to 100,000. To apply Min-Max scaling:\n",
    "\n",
    "Find the minimum and maximum values:\n",
    "\n",
    "age_min = 20\n",
    "age_max = 60\n",
    "income_min = 30000\n",
    "income_max = 100000\n",
    "Rescale the data:\n",
    "\n",
    "scaled_age = (age - age_min) / (age_max - age_min)\n",
    "scaled_income = (income - income_min) / (income_max - income_min)\n",
    "For example, if a person's age is 30 and their income is 50,000:\n",
    "\n",
    "scaled_age = (30 - 20) / (60 - 20) = 0.25\n",
    "scaled_income = (50000 - 30000) / (100000 - 30000) = 0.2857\n",
    "After Min-Max scaling, both features will be on a scale between 0 and 1, making them comparable and suitable for use in machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc5e978-0401-459e-baeb-c7864a06dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application.\n",
    "Ans:Unit Vector (Normalization) Technique is another method used in feature scaling to ensure that all features are on a similar scale. Unlike Min-Max scaling, which scales features to a specific range (0-1), Unit Vector scaling scales features to have a unit length (magnitude of 1). This is particularly useful when the magnitude of the features is important, such as in algorithms like cosine similarity.\n",
    "\n",
    "How Unit Vector Scaling Works:\n",
    "\n",
    "Calculate the Euclidean norm: For each feature vector, calculate its Euclidean norm, which is the square root of the sum of the squared values of its elements.\n",
    "Divide by the norm: Divide each element of the feature vector by its Euclidean norm. This scales the feature vector to have a unit length.\n",
    "Example:\n",
    "\n",
    "Suppose you have a feature vector x = [2, 4]. To apply Unit Vector scaling:\n",
    "\n",
    "Calculate the Euclidean norm:\n",
    "\n",
    "norm(x) = sqrt(2^2 + 4^2) = sqrt(20) ≈ 4.47\n",
    "Divide by the norm:\n",
    "\n",
    "scaled_x = [2/4.47, 4/4.47] ≈ [0.447, 0.894]\n",
    "Now, the scaled feature vector scaled_x has a unit length, meaning its magnitude is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdefce5b-0fd6-4145-be17-0803cb281556",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application.\n",
    "Ans:Principal Component Analysis (PCA) is a dimensionality reduction technique that transforms a high-dimensional dataset into a lower-dimensional dataset while preserving the most important information. It does this by finding a new set of uncorrelated variables, called principal components, that capture the maximum variance in the data.   \n",
    "\n",
    "How PCA Works:\n",
    "\n",
    "Center the data: Subtract the mean from each feature to center the data.\n",
    "Calculate the covariance matrix: Compute the covariance matrix of the centered data.\n",
    "Find the eigenvectors and eigenvalues: Calculate the eigenvectors and eigenvalues of the covariance matrix.\n",
    "Select the principal components: Choose the eigenvectors corresponding to the largest eigenvalues. These eigenvectors represent the principal components that capture the most variance in the data.   \n",
    "Project the data onto the principal components: Project the original data onto the selected principal components to obtain the reduced-dimensional representation.   \n",
    "Example:\n",
    "\n",
    "Suppose you have a dataset with two features, x1 and x2. You want to reduce the dimensionality to one.   \n",
    "\n",
    "Center the data: Subtract the mean from each feature.\n",
    "Calculate the covariance matrix: Compute the covariance matrix of the centered data.\n",
    "Find the eigenvectors and eigenvalues: Calculate the eigenvectors and eigenvalues of the covariance matrix.\n",
    "Select the principal component: Choose the eigenvector corresponding to the largest eigenvalue.\n",
    "Project the data: Project the original data onto the selected principal component to obtain the reduced-dimensional representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55cc7d8-8e7b-4edf-b37f-65b5fd23ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept.\n",
    "Ans:PCA and Feature Extraction\n",
    "\n",
    "PCA (Principal Component Analysis) is a powerful technique for feature extraction. Feature extraction involves transforming raw data into a new set of features that are more informative or easier to analyze. PCA achieves this by finding a new set of uncorrelated variables, called principal components, that capture the maximum variance in the data.   \n",
    "\n",
    "How PCA is Used for Feature Extraction:\n",
    "\n",
    "Dimensionality Reduction: PCA can reduce the dimensionality of a dataset by selecting a subset of the principal components that capture most of the variance. This can simplify the model and improve its computational efficiency.\n",
    "Noise Reduction: PCA can help to remove noise from the data by projecting it onto the principal components that capture the signal.\n",
    "Feature Engineering: PCA can be used to create new features that are more informative and less correlated. These new features can be used as input to other machine learning models.\n",
    "Example:\n",
    "\n",
    "Suppose you have a dataset with 100 features representing different sensor measurements. You want to reduce the dimensionality of the data while preserving the most important information.\n",
    "\n",
    "Apply PCA: Apply PCA to the dataset to find the principal components.\n",
    "Select Principal Components: Select the top k principal components that capture most of the variance in the data.\n",
    "Project Data: Project the original data onto the selected principal components to obtain the reduced-dimensional representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb29f8b-a0f6-4e1a-8a16-0328d3a913ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data.\n",
    "Ans:Using Min-Max Scaling for Feature Preprocessing in a Food Delivery Recommendation System\n",
    "Understanding the Problem:\n",
    "In a food delivery recommendation system, it's important to have features on a comparable scale to ensure that all features contribute equally to the recommendation process. Min-Max scaling is a suitable technique for this purpose.\n",
    "\n",
    "Applying Min-Max Scaling:\n",
    "\n",
    "Identify Numerical Features:\n",
    "\n",
    "Identify the numerical features in your dataset, such as price, rating, and delivery_time.\n",
    "Determine the Scaling Range:\n",
    "\n",
    "Decide on the desired scaling range. For Min-Max scaling, the typical range is 0 to 1.\n",
    "Calculate Minimum and Maximum Values:\n",
    "\n",
    "Find the minimum and maximum values for each numerical feature.\n",
    "Apply the Formula:\n",
    "\n",
    "Use the following formula to scale each feature:\n",
    "scaled_feature = (feature - min_value) / (max_value - min_value)\n",
    "For example, if the price feature ranges from 100 to 500, and a specific restaurant has a price of 300, the scaled price would be:\n",
    "scaled_price = (300 - 100) / (500 - 100) = 0.5\n",
    "Scale the Data:\n",
    "\n",
    "Apply the formula to each data point for the selected features.\n",
    "Benefits of Min-Max Scaling in Recommendation Systems:\n",
    "\n",
    "Ensures Feature Comparability: By scaling features to a common range, Min-Max scaling ensures that all features contribute equally to the recommendation process, preventing features with larger magnitudes from dominating the results.\n",
    "Improves Model Performance: Many machine learning algorithms, such as collaborative filtering and content-based filtering, benefit from having features on a similar scale.\n",
    "Interpretability: Scaled features can be easier to interpret and understand, as they are expressed in a standardized range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293067b-c95c-4cc7-957c-cf42ae20fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset.\n",
    "Ans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf0354c-b437-40f7-a29d-de4582734600",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1.\n",
    "Ans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cdeade-d32b-4e65-92d3-7a993123770b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889ad30-f359-4ae5-800d-e9c440337166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf598c7-d3ab-4907-af03-51d30d75b1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98badc79-b090-4ce8-94e3-9b239d3bc659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6450aa56-385f-4b9f-9616-8e1c2a8f8ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
